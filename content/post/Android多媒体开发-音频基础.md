---
title: "Android多媒体开发-音频基础"
description: "本文略讲了Android多媒体开发中音频的基础知识"
keywords: "Android,音视频开发,音频"

date: 2020-10-25T20:43:00+08:00

categories:
  - Android
  - 音视频开发
tags:
  - Android
  - 音视频开发
  - 音频

url: post/B5D25365B7A74DAFB431CAF09ECC875A.html
toc: true
---

本文略讲了Android多媒体开发中音频的基础知识。

<!--More-->

本文的内容不涉及平台，为基础知识的讲解。

作为一个 Android 菜鸟，进入公司后，接手的是即时通讯的模块。其中涉及到了音频、视频、图片、文本等功能的开发和维护。故在这里将学习的知识一一记录下来。

## 简介

音频是个专业术语，音频一词已用作一般性描述音频范围内和声音有关的设备及其作用。**人类能够听到的所有声音都称之为音频**，它可能包括噪音等。

现实生活中，我们听到的声音都是时间连续的，我们称为这种信号叫**模拟信号**。模拟信号需要进行数字化以后才能在计算机中使用。

人耳所能听到的声音，人类能够听到的声音的频率区间是：[20Hz, 20KHz]，即最低 20 赫兹，最高 2 万赫兹。因此音频文件格式的最大带宽是20KHZ。

根据采样定理，**只有采样频率高于声音信号最高频率的 2 倍时，才能把数字信号表示的声音还原成为原来的声音**。所以音频文件的采样率一般在40~50KHZ，即 4万 到 5万赫兹。

## 概念

下面是一个典型的声波曲线：

![声波曲线形状](/imgs/声波曲线形状.webp)

### 声音的部分物理参数

**振幅**

表示质点离开平衡位置的距离，反映从波形波峰到波谷的压力变化，以及波所携带的能量的多少。高振幅波形的声音较大；低振幅波形的声音较安静。在声波曲线中的表现是 AB 之间的距离（Y轴上的绝对值），距离越大，则振幅越大，能量越高。

**周期**

描述波形变形变化的周期。从零到波峰，再到波谷，再到零，这一时间的持续视为一个周期。即图中橙色段(CD)、蓝色段(DE)。周期记作 T。

**频率**

声波的频率是指某一个点在单位时间内振动的次数。以赫兹（Hz）为单位测量，描述每秒周期数。频率越高，音乐音调越高。记作 f，f * T = 1。即频率是周期的倒数。

### 声音的部分属性

**音调**

音调和声音的频率密切相关，各种声源发生的频率千差万别，使得声波丰富多彩。频率高，音调也高，声音尖锐；反之，频率低，音调也低，声音低沉。

**音色**

音色和波形密切相关，每一种声音都有各自的基本波形，称为基波。不同声音的基波中混入的谐波有多有少，导致音质变化多端，也就是音色的不同。基波中混入的谐波越多，也就是泛音越多，听起来就更悦耳。高频的泛音多，声音则变得沉重、庄严、厚实。

**音量**

声音的大小和能量密切相关，能量高，声音就强；能量低，声音则弱。音量的大小通常以分贝为单位来衡量。人耳刚能听见的声强是 0 分贝，普通谈话的声强是 60-70 分贝，而使人耳产生疼痛感觉的声强是 120 分贝。

### 数字化音频概念

#### 采样点

上面提到过，现实生活中，我们听到的声音都是时间连续的，使用数学形式表达出来，就是一条光滑的声波曲线。但是这样的连续过程在计算机中是不能被量化的，所以需要取样。取样就是将连续的过程间断化，变得可量化。

举个简单的例子。视频中有视频帧率这一说。视频帧率（Frame rate）是用于测量显示帧数的量度，单位为每秒显示帧数(Frames per Second，简称 FPS）。由于人类眼睛的特殊生理结构，如果所看画面之帧率高于16的时候，就会认为是连贯的，此现象称之为视觉停留。这也就是为什么电影胶片是一格一格拍摄出来，然后快速播放的原因。

这就是一个典型的将人眼的连续视觉间断化的案例。音频取样也是同样的道理。

从声波曲线中，我们可以知道，声音是可用数字衡量的。这就是将声音的模拟信号数字化的基础。音频采样得到的数值如下，绿色竖线与声波曲线的交点便是取样点。取样点的横坐标代表取样时间点，纵坐标代表声音的强度：

![声音模拟信号数字化](/imgs/声音模拟信号数字化.webp)

#### 采样频率

采样频率是**单位时间内对模拟信号的采样次数**。采样频率越高，声音的还原就越真实越自然，数据量也就越大。采样频率一般分为以下几个等级：

- 8KHz：电话所用的采样率。人们讲话的声音质量能达到 5kHz 的采样率。8KHz 的采样率对于人的说话已经足够
- 22.05KHz：FM 广播的声音品质，适用于语音和中等品质的音乐
- 44.1KHz：最广泛，最常见的采样率标准，在通常的开发中，理论上的CD音质界限，一般的开发中，我们只会用到这个采样率
- 48KHz：相比于 44.1KHz 更加精确一些。高于 48KHz 的采样频率，人耳已无法辨别出来了。所以在电脑上没有多少使用价值

#### 采样位数

采样位数是**每个采样点能够表示的数据范围**。采样位数通常有 8bits(1 个字节) 或 16bits(2 个字节) 两种。**8 位比特是低品质，16 位比特是高品质**。

- 采样位数客观地反映了数字声音信号对输入声音信号描述的准确程度。8 位代表 2 的 8 次方--256，16 位则代表 2 的 16 次方--64K。一段相同的音乐信息，16 位声卡能把它分为 64K 个精度单位进行处理，而 8 位声卡只能处理 256 个精度单位。故采样位数越大，所能记录声音的变化度就越细腻，相应的数据量就越大。**16 bits 是最常见的采样精度**。
- 16 位二进制数的最小值和最大值，对应的十进制数是 0 和 65535，换算成分贝，就是 96.32 分贝。人耳的无痛苦极限声压是 90 分贝，96 分贝在普通应用中足够使用。
- 采样位数是 16 位时，96 分贝内的模拟波，经量化后，不会产生削波失真，即声音信号不会有任何的丢失。超过 96 分贝的声音，数字化后，可能会产生失真。从数据上分析，超过96分贝，则超过了16位数的最大表示范围，多出的数据便会丢失；对于声音而言，则产生了失真。

#### 比特率

比特率也叫码率，是指将模拟声音信号转换成数字声音信号后，单位时间内的二进制数据量。在相同的编码格式下，比特率越大的音质就越好（不同格式，传输机制，算法不同，无法比较）。单位是 bps（bit per second，位/秒）。通常使用 kbps(千位/秒)或者 Mbps(兆位/秒)。

根据网友的**[研究测试](https://bbs.kafan.cn/thread-746782-1-1.html)**，常见的编码格式，推荐码率如下：

- OGG 的优势范围：>= 96K
- AAC 的优势范围：
   - AAC LC：>= 256K
   - AAC HE：48K - 96K
- Mp3 的优势范围：>= 192K
- WMA 的优势范围：>= 128K

根据码率的定义可知，码率是可以计算出来的。其公式为：码率 = 采样率 * 采样位数 * 声道数。

假如是 CD 音质，采样率 44.1KHz，采样位数 16bit(2 byte)，立体声(双声道)。那么码率为 44.1 * 1000 * 16 * 2 = 1411200 bps = 0.1682281494 Mbps，那么录制一分钟的音乐，录制的音频大小是 0.1682281494 * 60 = 10.093688964 MB。大概为 10.1 MB。通常 IM 消息体中的语音消息，便可以以此为参照，测算内存占用等一系列性能问题。

#### PCM

PCM（Pulse Code Modulation），即脉冲编码调制，对声音进行采样、量化过程，未经过任何编码和压缩处理。我们常说的 PCM 数据便是数字音频中最原始的、未经处理的音频数据。

PCM 数据是最原始的音频数据，完全无损，所以 PCM 数据音质优秀，体积庞大。这些特点注定了其不方便存储和传输。为了解决体积庞大的问题，需要对数据进行压缩，这就涉及到了音频格式。后面讲解。

#### 声道

声道也就音轨，声道数是指支持能不同发声的音响的个数，它是衡量音响设备的重要指标之一

在三维空间中，声源是有确定的位置，声音有确定的方向来源。声源与人的两耳距离是不同的，声音到达人的两耳的时间是不同的。人体可以通过声音到达人耳的不同时间来确定声源的位置，这就是**双耳效应**。

声道，立体声的概念都由”双耳效应“引出。我们把声音传向左耳的通道叫做"左声道"，把声音传向右耳的通道叫做"右声道"。这就是音频中常见的双声道的由来。而单声道音频就是指只剩下"左声道"或者"右声道"的音频。

立体声是一个几何概念，指具有立体感的声音。自然界发出的声音是立体声。但如果我们把这些立体声记录后重放，所有的声音都从一个扬声器放出来，这种重放声与原声音相比就不是立体的了，原来的空间感消失了。这种重放声称为单声。

如果从记录到重放整个系统能够在一定程度上恢复原声音的空间感（不可能完全恢复），那么，这种具有一定程度的方位层次感等空间分布特性的重放声，就称为立体声。

例如在演唱会上，用两个相距不太远的传声器记录歌手的声音。这样当歌手在舞台上由左向右、边走边唱地走过时，下面的听众就会感到好像歌手就在自己面前由左向右、边走边唱地走过一样。这就是声音很有立体感的体现，这就是双声道立体声录音。

立体声通常用 2 个声道记录便可以重现了。而部分立体声却采用了 4 个声道来记录。

**小例子**

在一首歌中，我们知道有人声和节拍两种声音。有时候，我们觉得节拍很好听，人声不行，不想要人声，想要消除人声。该怎么做呢？

我们可以把双声道立体声看成 4 个部分，1 称为人声，是两声道相同的部分，2、3、4 称为节拍声，是两声道不同的部分，2 是两声道相反的部分，3 是左声道特有的部分，4 是右声道特有的部分。

1. 人声消除的方法：新建左声道 = 原左声道 - 原右声道，新建右声道 = 原右声道 - 原左声道。表现为 1 的部分将消失。(例如：左声道数据 [4,2]，右声道数据 [4, 4]，左 - 右 的结果是 [0, -2]，相同的部分被消除了)
2. 单道混音的方法：原左声道 + 原右声道，变成了一个声道。表现为 2 的部分将消失。

从上面两个例子可以看出，人声可以消除，但节拍声无法通过最基本的立体声混音消除。

#### 音频帧

音频数据是流式的，本身没有明确的一帧帧的概念。而音频帧是为了方便处理而出现的概念。在实际的应用中，一般约定俗成取 2.5ms~60ms 为单位的数据量为一帧音频。这个时间被称之为“采样时间”，其长度没有特别的标准，它是根据编解码器和具体的需求来决定的。当取 2.5ms~60ms 的采样时长时，1 秒内，可以有 400~17 个音频帧，如果取 20ms，一秒便可以有 50 个音频帧。如果我们把采样时间和采样频率对应起来，以 20ms 和 44.1KHZ 为例，那么一个采样市场内，可以有 44.1 / 50 = 0.882KHZ = 882HZ，即每 20 毫秒，采样 882 次。

继续讲音频帧，以最常见的音频格式---MP3为例，MP3格式由两部分组成。
- 名为"ID3"的部分：用来存储歌名、演唱者、专辑、音轨数等信息
- 音频帧：音频数据以帧(frame)为单位存储。
   - 帧头：每个音频帧都有自己的帧头，其中存储了采样率等解码必须的信息。所以在 MP3 中，每一帧都可以独立于文件存在和播放。
   - 音频数据：帧头之后存储着音频数据，这些音频数据是若干个 PCM 数据帧经过压缩算法压缩得到的。对于每一个音频帧，采用 CBR(恒定比特率) 的 MP3 数据，包含的 PCM 数据是固定的，而 VBR(可变比特率) 包含的数据大小是可变的。

下图是 MP3 音频格式的简单描述：

![MP3音频格式的简单描述](/imgs/MP3音频格式的简单描述.webp)

音频的基础知识就先讲到这，下一篇会讲解如何在 Android 中的拿到音频数据。

#### 音频格式

为了解决 PCM 存在的问题。过去几十年，先后诞生了一系列的音频格式。这些音频格式运用不同的方法对音频数据进行压缩。简单的理解，音频格式就是音频的压缩和存储技术的体现。按照在压缩过程中有无丢失数据，音频格式可以分为无损压缩和有损压缩两大类。

- **有损压缩**：有损压缩是利用了人类对声波中的某些频率成分不敏感的特性，允许压缩过程中损失一定的信息；虽然不能完全恢复原始数据，但是所损失的部分对理解原始图像的影响缩小，却换来了大得多的压缩比，即指使用压缩后的数据进行重构，重构后的数据与原来的数据有所不同，但不影响人对原始资料表达的信息造成误解。有损压缩适用于重构信号不一定非要和原始信号完全相同的场合。
- **无损压缩**：无损压缩格式则是利用数据的统计冗余进行压缩，可完全恢复原始数据而不引起任何失真。即指使用压缩后的数据进行重构（或者叫做还原，解压缩），重构后的数据与原来的数据完全相同。无损压缩用于要求重构的信号与原始信号完全一致的场合。无损压缩的压缩率受到数据统计冗余度的理论限制，一般为 2:1 到 5:1。

常见的音频格式如下：

##### CD(CDA)

CD 格式(CDA 格式)，即 CD 音轨格式(CD Audio Format)，是由索尼和飞利浦在1980年期间作为音乐传播的一个形式而设计和介绍的。**CD 音轨格式是无损压缩格式的一种**，它的声音基本上是忠于原声的。**CD 音频文件通常是以".cda"作为文件后缀名。**

注意：不能混淆 CD 格式和 CDA 格式。CD 还包括其他格式标准(如 CD-ROM，CD-ROM XA等)，音频格式只是其中一种。

##### WAVE

**WAVE 格式是微软公司开发的一种声音文件格式，它符合PIFF "Resource Interchange File Format"(RIFF) 文件规范**，用于保存 Windows 平台的音频信息资源，被 Windows 平台及其应用程序所支持。**WAVE 格式是无损压缩格式的一种，其文件后缀名是 .wav**。

##### AIFF

AIFF（Audio Interchange File Format）格式和 AU 格式，它们都和 WAV 非常相像，在大多数的音频编辑软件中也都支持它们这几种常见的音乐格式。**AIFF 是音频交换文件格式的英文缩写。是 Apple 公司开发的一种音频文件格式**。AIFF是苹果电脑上面的标准音频格式，属于QuickTime技术的一部分。**AIFF 格式是无损压缩格式的一种，其文件后缀名是 .aiff**。

##### MPEG

MPEG(Moving Picture Experts Group) 不是一个格式，而是一系列格式的组合。MEPG 是动态图象专家组的英文缩写，这个专家组始建于 1988 年，专门负责为CD建立视频和音频压缩标准。MPEG音频文件指的是 MPEG 标准中的声音部分即 MPEG 音频层。MPEG 含有格式包括：MPEG-1、MPEG-2、MPEG-Layer3、MPEG-4(即 MP1、MP2、MP3、MP4)。

##### MP3

Mp3 格式诞生于八十年代的德国，所谓的 MP3 也就是指的是 MPEG 标准中的音频部分。**Mp3 格式是有损压缩格式的一种，其文件后缀名是 .mp3**。MP3 音频的压缩比通常是 10：1~12：1。MP3 能基本保持低音频部分不失真，但是牺牲了声音文件中 12KHz~16KHz 高音频这部分的质量来换取文件的尺寸。相同长度的音乐文件，用 MP3 格式来储存，一般只有 WAVE 文件的 1/10。MP3 因为文件尺寸小，音质好，所以从问世之初开始，便成为了主流音频格式。直到现在，也还是主流格式之一。但是 MP3 音乐存在版权问题，因为 MP3 并没有版权保护技术，说白了也就是谁都可以用。

##### MIDI

MIDI（Musical Instrument Digital Interface）格式被经常玩音乐的人使用，MIDI 允许数字合成器和其他设备交换数据。**MIDI 格式是有损压缩格式的一种，其文件后缀名是 .mid**。MID 文件并不是一段录制好的声音，而是记录声音的信息，然后再告诉声卡如何再现音乐的一组指令。这样一个 MIDI 文件每存 1 分钟的音乐只用大约 5～10KB。MID 文件主要用于原始乐器作品，流行歌曲的业余表演，游戏音轨以及电子贺卡等。MID 文件重放的效果完全依赖声卡的档次。MIDI 格式的最大用处是在电脑作曲领域。

##### RealAudio

RealAudio 是 RealNetwoks 公司私有化客人的编解码器，在 1995 年首次发布。它包括通过一系列的音频进行编解码，从古老拨号 modem 的低速率格式到高质量的音乐。可用于网络媒体流，过去很多的互联网电台可以使用 RealAudio 作为一个他们进行节目的实时控制音频流，**近年使用得相对较少，让位与其他流行的格式**。real 的的文件格式主要有 RA（RealAudio）、RM（RealMedia，RealAudio G2）、RMX（RealAudio Secured）等。文件后缀名是 ".ra 或者 .ram"。

##### WMA

WMA (Windows Media Audio) 格式是来自于微软的重量级选手，后台强硬。**WMA 是主流音频格式之一**。WMA 音质要强于 MP3 格式，更远胜于 RA 格式。"**WMA 格式是有损压缩格式的一种**，其文件后缀名是 .wma"。它和日本 YAMAHA 公司开发的 VQF 格式一样，是以减少数据流量但保持音质的方法来达到比 MP3 压缩率更高的目的，WMA 的压缩率一般都可以达到 18:1 左右。WMA 的另一个优点是内容提供商可以通过 DRM（Digital Rights Management）方案如 Windows Media Rights Manager 7 加入防拷贝保护。这种内置了版权保护技术可以限制播放时间和播放次数甚至于播放的机器等等，这对被盗版搅得焦头烂额的音乐公司来说可是一个福音，另外 WMA 还支持音频流(Stream)技术，适合在网络上在线播放，作为微软抢占网络音乐的开路先锋可以说是技术领先、风头强劲，更方便的是不用像 MP3 那样需要安装额外的播放器，而Windows 操作系统和 Windows Media Player 的无缝捆绑让你只要安装了 windows 操作系统就可以直接播放 WMA 音乐。

##### VQF

VQF 音频格式，即TwinVQ（Transform－domain Weighted Interleave Vector Quantization），是由 NTT（Nippon Telegraph and Telephone）与 Yamaha(雅马哈) 共同开发。"**VQF 格式是有损压缩格式的一种**，其文件后缀名是 .vqf"。VQF 音频可以用雅马哈的播放器播放，音频压缩率比标准的 MP3 音频压缩率高出近一倍，可以达到 18:1 左右甚至更高。在相同情况下，压缩后的 VQF 文件体积比 MP3 小 30%～50%，更利于网上传播，同时音质极佳，接近CD音质(16位 44.1kHz 立体声)。VQF 格式可以说技术上也是很先进的，但是由于**技术标准尚未公开、不支持流(STREAM)等原因，这种格式使用不太广泛**。

##### Ogg

Ogg 是完全免费、开放和没有专利限制的音频格式。Ogg 是一个自由且开放标准的容器格式，由 Xiph.Org 基金会所维护。“Ogg” 这个词汇通常意指 Ogg Vorbis 此一音频文件格式，也就是将 Vorbis 编码的音效包含在 Ogg 的容器中所成的格式。在以往，.ogg 此一扩展名曾经被用在任何 Ogg 支持格式下的内容；但在 2007 年，Xiph.Org 基金会为了向后兼容的考量，提出请求，将 .ogg 只留给 Vorbis 格式来使用。Xiph.Org 基金会决定创造一些新的扩展名和媒体格式来描述不同类型的内容，像是只包含音效所用的 .oga、包含或不含声音的影片所用的 .ogv 和程序所用的 .ogx。所以，就目前来说，Ogg = OggVorbis。**Ogg 是有损压缩格式的一种**。

##### AMR

AMR全称 Adaptive Multi-Rate，自适应多速率编码，**主要用于移动设备的音频，压缩比比较大，但相对其他的压缩格式质量比较差，是有损压缩的一种**。多用于人声，通话。AMR 分为 AMR-NB 和 AMR-WB 两种标准。其中 AMR-WB 全称为 "Adaptive Multi-rate - Wideband"，即 "自适应多速率宽带编码"，采样频率为 16kHz，是一种同时被国际标准化组织 ITU-T 和 3GPP 采用的宽带语音编码标准，也称 为 G722.2 标准。AMR-WB抗扰度优于AMR-NB。

##### APE

APE 是流行的数字音乐文件格式之一。**APE是一种无损压缩音频技术**。APE 的文件大小大概为 CD 的一半。APE 由软件 Monkey's audio 压制得到，开发者为 Matthew T. Ashland，源代码开放，因其界面上有只“猴子”标志而出名。

##### FLAC

FLAC 代表 Free Lossless Audio Codec，意为 "免费的无损音频压缩"。**FLAC 是一种完全开放的无损压缩音频技术**。和 APE 相比，FLAC 的编码和解码复杂程度要较低（解码运算量小、只需要整数运算），解码速度奇快，通常 FLAC 的解码速度比 APE 快 30%，标签和封面也可以完美写入。

##### AAC

AAC（Advanced Audio Coding），即高级音频编码。出现于 1997 年，**基于 MPEG-2 的音频编码技术，是一种有损压缩格式**。由 Fraunhofer IIS、杜比实验室、AT&T、索尼 等公司共同开发，目的是取代 MP3 格式。2000年，MPEG-4 标准出现后，AAC 重新集成了其特性，加入了 SBR 技术和 PS 技术，为了区别于传统的 MPEG-2 AAC 又称为 MPEG-4 AAC。AAC 混合了 SBR 技术之后，得到了 AAC+(又称 HE-AAC)。SBR 代表的是 Spectral Band Replication（频段复制）。SBR 的目的是解决在低码流下，减少带宽和降低采样率或产生令人不快的噪音信号的问题。这意味着采用了 SBR 后，在低码流下提供全带宽的编码而不会产生产生多余的信号。

##### ALAC

ALAC 即 Apple lossless audiocodec 的缩写，**是苹果公司开发的一种无损音频格式，是对 AIFF 的压缩，扩展名是 m4a**，类似于 FLAC 是对 WAV 的压缩一样，自然文件小。ALAC 同 AAC 一样是 MPEG-4 封装。

##### DSD

DSD 是 Direct Stream Digital 的缩写，表示直接比特流数字编码，由 Sony 与 Philips 在 1996 年共同发展。DSD 的优缺点都很突出，相比 WAV，音质确实好多了。缺点也是，文件太大太大，能硬解DSD的芯片还是少数。故**是一种非主流的音频格式**。严格来讲，DSD 对标的应该是 PCM。打个比方,PCM 是对着原图去描点,但是这个描点你再怎么精确总是会有点小误差，而 DSD 就是对着原图画轮廓，但是这个轮廓比 PCM 的描点更精确。**虽然 DSD 比起 PCM 有着种种优势，但是 DSD 有个硬伤，录音后期混音制作的时候无法使用 DSD，只有 PCM 才能做混音处理**。

##### OPUS

**Opus 是一个有损声音编码的格式**，由 Xiph.Org 基金会开发，之后由 IETF 互联网工程任务组进行标准化，**目标用希望用单一格式包含声音和语音，取代 Speex 和 Vorbis(两者由 Xiph.Org 开发)，且适用于网上上低延迟的即时声音传输**。标准格式定义于 RFC 6716 文件。Opus 格式是一个开放格式，使用上没有任何专利或限制。Opus 可以处理各种音频应用，包括 IP 语音、视频会议、游戏内聊天、流音乐、甚至远程现场音乐表演。它可以从低比特率窄带语音扩展到非常高清音质的立体声音乐。

Opus 融合了 Skype 的 SILK 和 XVID 的 CELT 技术，拥有比 AAC、OGG 等其它有损格式更大的压缩率。它已经被标准化互联网组织 IETF 认证通过，是 AAC 后新一代的编码格式。OPUS 的特点如下：

- 6 kbs 到 510 kbs 的比特率；单一频道最高 256 kb/s
- 采样率从 8 kHz（窄带）到 48 kHz（全频）
- 帧大小从 2.5ms 到 60ms
- 支持恒定比特率（CBR）、受约束比特率（CVBR）和可变比特率（VBR）
- 支持语音（SILK层）和音乐（CELT层）的单独或混合模式
- 支持单声道和立体声；支持多达 255 个音轨（多数据流的帧）
- 可动态调节比特率，音频带宽和帧大小
- 良好的稳健性丢失率和数据包丢失隐藏（PLC）
- Opus 格式使用了 Ogg 容器，所以继承了 Vorbis 注释

在 Opus 的开发阶段，低码率下 Opsu 完胜曾经优势明显的 HE AAC(AAC+)，中码率就已经可以媲敌码率高出 30% 左右的 AAC 格式，而高码率下更接近原始音频。而在 Opus 稳定之后，根据**[网友测试](https://www.zhihu.com/question/55194135/answer/143683190)**。**opus1.2 发布后，大幅改善了低码率下的音质，已经全方位比 aac 好了**。值得注意的是，opus 是强制性 48KHZ 采样，不过也有个 Opus Custom 可选标准，用这个可以 44.1k，不过官方是说“除非是特殊应用不然非常不建议这样做”。官方强制 48k 的理由是便于优化，并且很多低端设备是48k输出。所以**采样率啥的选择还是要根据实际设备来**。更具体的可以看 opus 官网的编码码率推荐指南。总体来说，**Opus 是值得关注的一个音频格式**。

下面来张上面介绍的音频格式的总结图：

![音频格式总结图](/imgs/音频格式总结图.webp)

## 尾语

上面介绍一些音频相关的知识，以及常见的音频编码格式。如果有错误，望指出。接下来的内容就属于这些内容的具体实现了。后面会分批讲解。
